{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c19468",
   "metadata": {},
   "source": [
    "# Preprocessing Script for EPSC Traces #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18abb79",
   "metadata": {},
   "source": [
    "## Description ## \n",
    "\n",
    "This script is a pilot preprocessing script for EPSC traces, in need of validation. \n",
    "\n",
    "## Data Dictionary: ## \n",
    "\n",
    "- **Processed_EPSCs**: Data from \"Only Single EPSCs Sheet 1\". This data has already been preprocessed  manually. \n",
    "\n",
    "- **Unprocessed_EPSCs**: Data from \"171023_010.txt\" that has not been processed. After processing, it will be compared with Processed_EPSCs. This file in particular is being used because full traces can be visualized. The first column of this data is the time points, the second column of it is the current recordings\n",
    "\n",
    "\n",
    "\n",
    "Notes from Juan:\n",
    "The criteria used for decay is, as discussed also, decay tau < 0.8 milliseconds and end level of fitting < 10pA.\n",
    "The criteria for rise time that I used now was 20-80% < 0.2 milliseconds. Again, only based on operational criteria.\n",
    "\n",
    "A couple of more points:\n",
    "- We can change the 20-80% to 10-90% at any time. \n",
    "- to detect the onset of the EPSC the criteria that I used was 5x the standard deviation of the baseline.\n",
    "- Decay fitting started 5 sample points after peak\n",
    "- EPSCs in the spreadsheet are not further noise filtered after acquisition (lowpass 6 kHz at hardware)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea03e28",
   "metadata": {},
   "source": [
    "## Initalization ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1184b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure all libraries are present\n",
    "import numpy as np \n",
    "import xlrd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb949158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for reading in data \n",
    "\n",
    "def read_excel(excel_path, sheet_no = 0):\n",
    "    book = xlrd.open_workbook(excel_path)\n",
    "    sheet = book.sheet_by_index(sheet_no)\n",
    "    return numpy.array([list(map(lambda x : x.value, sheet.row(i))) for i in range(sheet.nrows)])\n",
    "\n",
    "def read_txt(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f5f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Specify the file name \n",
    "# unprocessed_filename = \"unprocessed_data.txt\"\n",
    "# unprocessed_epscs = read_txt(unprocessed_filename)\n",
    "# #Reshape the data so that every trace and its timepoints are a subarray\n",
    "# num_traces = 10\n",
    "# unprocessed_epscs = unprocessed_epscs.reshape(num_traces, -1, 2) #Shape is (10, 499968, 2) for prototype\n",
    "# #Access a single trace without time data by unprocessed_epsc[trace index][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf5b40",
   "metadata": {},
   "source": [
    "## Visualize Traces ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0456581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, 5, figsize=(30, 20))\n",
    "# axs = axs.flatten()\n",
    "# for i, trace in enumerate(unprocessed_epscs):\n",
    "#     timepoints = trace[:,0]\n",
    "#     current = trace[:,1]\n",
    "#     axs[i].plot(timepoints, current)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b60b8",
   "metadata": {},
   "source": [
    "## Preprocessing Checkpoints ##\n",
    "\n",
    "Email raw text: \n",
    "minimum peak amplitude (20pA), maximum 10-90% or 20-80% rise time (0.2 - 0.3 ms), maximum decay tau (0.8 ms), and return to within 10pA of baseline within 10ms after peak.  The baseline (mean and s.d.) is calculated over a 1ms period beginning 2ms before the peak, and the beginning of the EPSC is when it exceeds baseline by 5 standard deviations\n",
    "\n",
    "### *Checkpoint 1: EPSC Peaks are Aligned* ###\n",
    "\n",
    "The peak of the EPSC must correspond to the index given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee387b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_peak_alignment(unprocessed_EPSCs, peak_index):\n",
    "    # Iterate through columns\n",
    "    processed_EPSCs = unprocessed_EPSCs.copy()\n",
    "    count = 0\n",
    "    for col in processed_EPSCs.columns:\n",
    "        # Find the index of the maximum value in the column\n",
    "        max_index = processed_EPSCs[col].idxmax()\n",
    "\n",
    "        # Check if the index matches the specified peak_index\n",
    "        if max_index != peak_index:\n",
    "            # Drop the column if the index doesn't match\n",
    "            processed_EPSCs.drop(col, axis=1, inplace=True)\n",
    "            count +=1\n",
    "    print(f\"Dropped {count} unaligned EPSC traces!\")\n",
    "    return processed_EPSCs\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa09d2",
   "metadata": {},
   "source": [
    "### *Checkpoint 2: EPSC Peaks Return to Baseline Within 10ms* ###\n",
    "The EPSC must return to within 10pA of the baseline within 10ms after the peak. This means that after the peak, the function will check if everything beyo\n",
    "\n",
    "600 timepoints = 12ms \n",
    "50 timepoints = 1ms\n",
    "\"Within 10ms of peak\" indicates \"within 500 timepoints of peak\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d647669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_baseline_return(unprocessed_EPSCs,baseline_mean,peak_index):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285fbc1",
   "metadata": {},
   "source": [
    "### *Checkpoint 3: Eliminate Double Peaks* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad75876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_double_peaks(unprocessed_EPSCs,current_threshold, peak_index, time_threshold ):\n",
    "    #Late double peaks\n",
    "    df = unprocessed_EPSCs.copy()\n",
    "    count = 0\n",
    "    for col in df.columns:\n",
    "        # Extract values in the specified range of rows for the column\n",
    "        after_peak_values = df.loc[peak_index+time_threshold:, col]\n",
    "        before_peak_values = df.loc[0:peak_index-30,col]\n",
    "        # Check if any value violates the threshold\n",
    "        if any(after_peak_values > current_threshold):\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            count += 1\n",
    "        if any(before_peak_values > 300):\n",
    "            print(\"Found before peak issue\")\n",
    "            df.drop(col,axis=1,inplace=True)\n",
    "            \n",
    "    print(f\"Dropped {count} EPSCs with double peaks\")\n",
    "    return df \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bb2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
